{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65332031 1.12207031 0.04629517 0.42285156 1.79980469]\n",
      " [0.36181641 0.83203125 0.41064453 1.06542969 0.79394531]\n",
      " [0.58642578 0.79248047 0.14099121 1.09667969 0.76806641]\n",
      " ...\n",
      " [1.09863281 0.90429688 1.73046875 0.62744141 1.0390625 ]\n",
      " [0.96191406 0.86914062 1.35351562 1.16796875 1.04785156]\n",
      " [1.72753906 0.57080078 0.75927734 0.54296875 1.79980469]]\n"
     ]
    }
   ],
   "source": [
    "#importer dataset\n",
    "data=pd.read_csv(\"Data_alphabet.csv\")\n",
    "x=data.iloc[:,1].values\n",
    "x1=data.iloc[:,1]\n",
    "X2=np.zeros((727,5))\n",
    "for i in range (727):\n",
    "    SS=np.array([0,0 ,0, 0 ,0])\n",
    "    res = ast.literal_eval(x1[i])\n",
    "    while( len(res) <5):\n",
    "        res.append(180)\n",
    "    arr=np.array(res,np.float16)*1/100\n",
    "    X2[i]=arr\n",
    "\n",
    "print ( X2) \n",
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
      " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(727, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apercu des donnÃ©es\n",
    "print(y)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.37792969 0.46679688 1.53613281 0.44873047 1.57128906]\n",
      " [1.54785156 0.83984375 1.1015625  0.40136719 1.50976562]\n",
      " [1.48535156 1.40136719 0.07550049 0.98583984 0.17675781]\n",
      " [0.63671875 1.33007812 1.54003906 0.49121094 1.40136719]\n",
      " [1.69726562 0.75048828 0.73388672 0.21374512 1.79980469]\n",
      " [0.72949219 1.42578125 0.41625977 0.96679688 1.11425781]\n",
      " [0.87792969 1.10351562 1.24023438 0.80957031 1.36914062]\n",
      " [1.07128906 0.95898438 1.3515625  0.88867188 1.13085938]\n",
      " [0.62646484 1.26855469 0.24938965 0.90185547 1.29101562]\n",
      " [0.86621094 0.98486328 0.32128906 1.42773438 1.79980469]\n",
      " [1.12207031 0.78173828 1.46777344 0.61816406 1.41113281]\n",
      " [0.53417969 1.35742188 0.80273438 0.99951172 1.70605469]\n",
      " [0.51025391 0.62011719 1.10449219 0.97998047 1.41503906]\n",
      " [1.07226562 0.91015625 1.48339844 0.42651367 1.5078125 ]\n",
      " [0.78613281 1.0078125  1.58886719 0.3269043  1.68847656]\n",
      " [0.83251953 0.98193359 0.39868164 1.53222656 1.11914062]\n",
      " [1.44335938 0.37988281 1.75585938 0.42651367 1.39257812]\n",
      " [1.33496094 0.60791016 1.54882812 0.59375    1.31347656]\n",
      " [1.25976562 0.72607422 1.55664062 0.59130859 1.26660156]\n",
      " [0.73828125 1.38085938 0.59716797 1.16796875 1.51660156]\n",
      " [0.54296875 1.32910156 0.29248047 0.92675781 1.3671875 ]\n",
      " [0.91064453 0.77246094 0.93896484 0.97851562 1.79980469]\n",
      " [0.51757812 1.24023438 1.69140625 0.33837891 1.39453125]\n",
      " [0.32495117 1.63867188 0.38037109 1.25488281 1.79980469]\n",
      " [0.78417969 0.98925781 1.25097656 1.49121094 0.2668457 ]\n",
      " [1.13378906 0.80761719 0.83447266 0.82373047 1.79980469]\n",
      " [0.57910156 0.859375   0.23681641 1.0390625  0.80419922]\n",
      " [1.72460938 0.72509766 1.1484375  0.60644531 1.04589844]\n",
      " [0.56738281 1.31152344 0.67333984 1.08105469 1.76660156]\n",
      " [0.49438477 1.62207031 0.53857422 1.21972656 1.16992188]\n",
      " [1.18261719 0.77685547 1.20898438 0.43188477 1.79980469]\n",
      " [1.15039062 1.16210938 0.22412109 0.83251953 0.75585938]\n",
      " [0.18737793 0.88623047 0.91064453 0.33251953 0.51660156]\n",
      " [0.95263672 0.88427734 1.45996094 0.41333008 1.69042969]\n",
      " [0.82226562 0.92138672 0.79394531 1.1796875  0.44213867]\n",
      " [0.77832031 1.34765625 0.54882812 0.89746094 0.92333984]\n",
      " [0.60693359 0.89550781 0.27368164 1.12207031 0.69335938]\n",
      " [0.90820312 0.95605469 1.02148438 0.86132812 1.65332031]\n",
      " [1.12597656 0.71630859 1.68164062 0.44848633 1.42871094]\n",
      " [1.17578125 0.80175781 1.53125    0.48925781 1.40136719]\n",
      " [1.06347656 0.98144531 0.07403564 1.13867188 0.50439453]\n",
      " [0.99707031 0.84179688 1.59960938 0.40771484 1.55371094]\n",
      " [1.07324219 0.70751953 0.93603516 0.88330078 1.79980469]\n",
      " [0.31396484 1.61328125 1.15722656 0.33520508 1.62011719]\n",
      " [0.63427734 1.23144531 0.60302734 1.13183594 1.79980469]\n",
      " [0.44311523 1.74414062 1.79882812 0.24853516 1.05273438]\n",
      " [1.32714844 1.16015625 0.07226562 1.13476562 0.42553711]\n",
      " [0.90380859 1.08789062 1.2421875  0.93164062 1.23535156]\n",
      " [0.49780273 1.58984375 0.18188477 0.91015625 1.79980469]\n",
      " [0.3112793  1.62207031 0.37402344 1.29296875 1.79980469]\n",
      " [0.36694336 1.50488281 0.94628906 0.49902344 1.51660156]\n",
      " [1.4140625  0.58007812 1.55371094 0.4597168  1.39257812]\n",
      " [0.59375    1.32617188 0.30224609 0.89550781 1.33496094]\n",
      " [0.86523438 1.01855469 1.53125    0.64794922 1.33886719]\n",
      " [1.234375   0.45532227 1.62792969 0.38867188 1.69335938]\n",
      " [0.86669922 1.00292969 1.6484375  0.39086914 1.49023438]\n",
      " [0.71386719 1.1484375  0.56103516 1.17773438 1.79980469]\n",
      " [0.51220703 1.32421875 0.0378418  0.77392578 1.79980469]\n",
      " [0.75390625 1.07226562 0.27929688 1.79101562 1.48632812]\n",
      " [1.29003906 0.57177734 1.63769531 0.50830078 1.39257812]\n",
      " [1.07128906 0.83056641 1.50585938 0.53417969 1.45703125]\n",
      " [0.84863281 1.04296875 1.01855469 0.75292969 1.73730469]\n",
      " [0.87744141 1.01757812 1.40136719 0.80175781 1.30273438]\n",
      " [0.90039062 0.98828125 1.32910156 1.49511719 0.68798828]\n",
      " [1.3515625  0.58203125 1.59863281 0.55664062 1.31152344]\n",
      " [0.92626953 0.81494141 0.0949707  1.10839844 0.48510742]\n",
      " [0.90820312 0.89990234 0.75292969 1.05566406 0.29467773]\n",
      " [1.44140625 0.80371094 1.12890625 0.37353516 1.65234375]\n",
      " [0.75146484 0.98291016 0.69482422 1.17089844 1.79980469]\n",
      " [0.54589844 0.57763672 0.1628418  0.19470215 1.79980469]\n",
      " [1.52832031 0.76757812 0.93359375 1.09960938 1.0703125 ]\n",
      " [0.78515625 1.02246094 0.79052734 1.12109375 1.68164062]\n",
      " [1.4921875  0.53173828 1.49414062 0.65771484 1.22460938]\n",
      " [0.89550781 0.96044922 1.54492188 0.69726562 1.30078125]\n",
      " [1.06640625 1.36523438 0.62646484 1.1875     1.15527344]\n",
      " [1.07519531 0.89355469 1.36230469 0.70068359 1.3671875 ]\n",
      " [1.14257812 0.60449219 1.42089844 0.43212891 1.79980469]\n",
      " [0.79394531 0.69238281 1.30371094 0.4909668  1.48144531]\n",
      " [0.65185547 1.15820312 1.51367188 0.13427734 1.36914062]\n",
      " [1.19824219 0.65136719 1.53613281 0.51367188 1.50097656]\n",
      " [0.81640625 1.625      0.73632812 0.32006836 1.69726562]\n",
      " [1.37890625 0.60595703 0.95019531 0.66552734 1.79980469]\n",
      " [0.65332031 1.12207031 0.04629517 0.42285156 1.79980469]\n",
      " [0.87011719 1.10058594 0.68310547 0.94628906 1.79980469]\n",
      " [0.80957031 0.61865234 1.61523438 0.58789062 1.76855469]\n",
      " [1.18066406 0.79394531 1.54394531 0.47753906 1.40332031]\n",
      " [0.74609375 1.06835938 1.73828125 0.46972656 1.25390625]\n",
      " [0.89501953 0.82324219 1.01074219 0.87109375 1.79980469]\n",
      " [0.47119141 1.57226562 0.56738281 1.19238281 1.14160156]\n",
      " [0.93164062 0.92578125 0.98583984 1.77636719 0.73388672]\n",
      " [1.20605469 0.52832031 1.49511719 0.93945312 1.23144531]\n",
      " [1.0390625  0.79443359 1.57421875 0.50146484 1.4921875 ]\n",
      " [1.00390625 0.86181641 1.20605469 0.52832031 1.79980469]\n",
      " [0.56298828 0.75732422 0.08557129 0.28051758 1.79980469]\n",
      " [1.77832031 0.78613281 1.06640625 0.68066406 1.04492188]\n",
      " [0.61865234 1.30957031 1.50585938 0.49682617 1.46777344]\n",
      " [0.88378906 1.05664062 1.01660156 0.75830078 1.68457031]\n",
      " [0.43432617 1.53027344 0.94482422 0.51269531 1.62109375]\n",
      " [1.29003906 0.63525391 1.57421875 0.56835938 1.33203125]\n",
      " [1.36621094 0.85546875 1.11035156 0.56103516 1.50585938]\n",
      " [1.02636719 0.78955078 1.5078125  0.47460938 1.60253906]\n",
      " [0.96191406 0.86914062 1.35351562 1.16796875 1.04785156]\n",
      " [0.92333984 1.07226562 1.42382812 0.50830078 1.47265625]\n",
      " [0.34790039 1.22363281 0.63183594 0.83789062 1.20605469]\n",
      " [1.45507812 1.56542969 0.00636292 1.05175781 0.1619873 ]\n",
      " [0.75390625 0.63427734 1.2734375  0.48071289 1.34277344]\n",
      " [0.94628906 1.09082031 1.24414062 0.79736328 1.32128906]\n",
      " [0.37573242 1.61621094 1.58398438 0.04187012 0.98242188]\n",
      " [0.89355469 1.07714844 1.22460938 0.90332031 1.30078125]\n",
      " [0.61083984 0.81054688 1.48046875 0.44311523 1.54492188]\n",
      " [0.30541992 0.86181641 0.703125   1.73046875 1.79980469]\n",
      " [0.60986328 1.10839844 0.83398438 1.1015625  1.74707031]\n",
      " [0.44287109 0.59667969 0.79199219 1.76855469 1.79980469]\n",
      " [1.02441406 0.82177734 1.28613281 1.171875   1.09570312]\n",
      " [0.96044922 0.93310547 1.35351562 0.91552734 1.23730469]\n",
      " [0.62158203 1.25292969 1.60253906 0.70703125 1.21582031]\n",
      " [1.08984375 0.83935547 1.07519531 0.59667969 1.79980469]\n",
      " [1.66601562 0.37426758 1.45214844 0.73681641 1.16992188]\n",
      " [1.09472656 0.625      1.22167969 0.65917969 1.79980469]\n",
      " [1.37402344 0.55517578 1.5859375  0.56640625 1.31835938]\n",
      " [0.72851562 0.54882812 1.10253906 1.56640625 1.45410156]\n",
      " [0.89501953 0.91210938 0.29614258 0.58007812 0.27709961]\n",
      " [0.86621094 0.95507812 0.86767578 1.31347656 1.39746094]\n",
      " [0.83251953 1.11328125 1.03515625 0.61865234 1.79980469]\n",
      " [0.83105469 0.88671875 1.33398438 1.46289062 0.21081543]\n",
      " [0.91894531 1.09667969 0.70556641 0.87939453 1.79980469]\n",
      " [0.58349609 0.70068359 0.23474121 0.98046875 0.70166016]\n",
      " [1.33886719 0.90380859 1.07519531 0.35473633 1.72753906]\n",
      " [0.92773438 0.91748047 0.29370117 1.58984375 1.25097656]\n",
      " [0.92822266 1.09082031 1.25097656 0.796875   1.33203125]\n",
      " [1.11328125 0.80957031 1.51464844 0.59326172 1.36914062]\n",
      " [0.38989258 1.38964844 0.90380859 0.63769531 1.52148438]\n",
      " [1.21289062 0.42163086 1.70214844 0.35644531 1.51171875]\n",
      " [0.95703125 0.82568359 1.62988281 0.453125   1.53515625]\n",
      " [0.66552734 1.30761719 0.68164062 0.94580078 1.79980469]\n",
      " [0.32958984 1.73339844 0.25683594 1.28027344 1.79980469]\n",
      " [0.93994141 1.08300781 1.47265625 0.72509766 1.1796875 ]\n",
      " [1.12890625 1.40625    0.71582031 1.73242188 0.2824707 ]\n",
      " [0.91699219 0.88232422 1.69335938 0.57666016 1.33105469]\n",
      " [1.32519531 0.86132812 1.11425781 0.87744141 1.22167969]\n",
      " [0.75927734 1.12890625 1.66503906 0.50292969 1.07421875]\n",
      " [1.22558594 0.70507812 0.94042969 0.72949219 1.79980469]\n",
      " [1.73632812 0.52099609 1.18652344 0.82617188 1.00292969]\n",
      " [1.65625    0.66113281 1.1328125  0.63232422 1.03027344]\n",
      " [0.59570312 1.16210938 0.39379883 1.44921875 1.79980469]\n",
      " [1.15820312 0.60449219 1.27734375 0.55908203 1.79980469]]\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test= train_test_split(X2,y,test_size=0.2)\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le modele svm\n",
    "classifier= SVC(kernel='linear',random_state= 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 15  4 12  2  4  0  9 10  0  0  3 18 16  2 16 18  1 12  2  0  6  4  1\n",
      " 18 16  0 12  6 18  1 12  6 11  5  9 12 19  1  9  0  5 12  9  2 12  4  1\n",
      " 12  1  4  4 19 18  2  5 12  1  0  0  0  0  2  4 12 18 17 12  4  0  6 12\n",
      "  4  4 13  5  2 11  1  5  4  1  4  0  9  4 18  9  2 12  1  4 13 10 11 10\n",
      "  4 18 18  0  9  0  2 12  1 12 12 16 10  0 12 16 12 12  0  3  5  2  4 18\n",
      "  5  1  0 18  1 16  1  5  0  2  5 12  9  4  6  2 16  5 18 11  9 12 18 18\n",
      "  2  5]\n",
      "[ 0 15 19 17 13  6 10  9  0  0  0  3  5 19 15 16 10  0 12  2  0 14  5  0\n",
      " 18  3  0  9  5 16  0 14 14 11 11  3 14 19  1 19  0  5  8  9 13 12  6 14\n",
      " 15  6 11  6 19 18 13  4 12 14  0  0  1  0  7 19 14 10  9  5  5  0  6 12\n",
      " 11 10  7 11  2 11  1  5  4  6 14  0  8  4 18  7  2 12  5 19 13 15 11  0\n",
      " 14  3 18 10  7 16 13 17 14  8 17 16  4  0  9  3 12 12  0  3  5  8  4 10\n",
      " 11 15  0 16  1 15  6 11 10 13 11  8  7  5  6  2 16  5 11 11  7 15 18 16\n",
      "  2 11]\n"
     ]
    }
   ],
   "source": [
    "#prediction sur le test set\n",
    "y_pred=classifier.predict(x_test)\n",
    "y_pred=np.array(y_pred,np.int8)\n",
    "print(y_pred)\n",
    "y_test=np.array(y_test,np.int8)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  1,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,\n",
       "         1,  0,  0,  0],\n",
       "       [ 3,  3,  0,  0,  0,  1,  3,  0,  0,  0,  0,  0,  0,  0,  3,  1,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  5,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  5,  0,  1,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  3,  3,  3,  0,  0,  0,  1,  2,  0,  0,  2,  0,\n",
       "         0,  0,  0,  3],\n",
       "       [ 0,  0,  0,  0,  1,  4,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  2,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  4,  1,  2,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1],\n",
       "       [ 2,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  3,  2,  0,  0,  7,  0,  3,  2,\n",
       "         0,  3,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         3,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  3,  1,  0,  0,  0,  0,\n",
       "         3,  0,  5,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  2]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomclasse(ypredct):\n",
    "    j=0\n",
    "    A=data.iloc[:,0]\n",
    "    if (ypredct==j):\n",
    "        return A[j]\n",
    "    if(ypredct==1):\n",
    "        j=j+1\n",
    "        return A[j*40]\n",
    "    if(ypredct<15):\n",
    "        while(j!= ypredct):\n",
    "            j=j+1\n",
    "        return A[j*39]\n",
    "    else:\n",
    "        while(j!= ypredct):\n",
    "            j=j+1\n",
    "        return A[j*37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gaaf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomclasse(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
